Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?

Идея, лежащая в основе мультиклассовой f-меры, заключается в вычислении одной бинарной f-меры для каждого класса, интересующий класс становится положительным, а все остальные – отрицательными классами. Затем эти f-меры для каждого класса усредняются с использованием одной из следующих стратегий:

	• "macro" усреднение вычисляет f-меры для каждого класса и находит
	их невзвешенное среднее. Всем классам, независимо от их размера,
	присваивается одинаковый вес.

	• "weighted" усреднение вычисляет f-меры для каждого класса и
	находит их среднее, взвешенное по поддержке (количеству
	фактических примеров для каждого класса). Эта стратегия
	используется в классификационном отчете по умолчанию.

	• "micro" усреднение вычисляет общее количество ложно
	положительных примеров, ложно отрицательных примеров и истинно
	положительных примеров по всем классам, а затем вычисляет
	точность, полноту и f-меру с помощью этих показателей.

Если вам необходимо присвоить одинаковый вес каждому примеру,
рекомендуется использовать микро-усреднение f1-меры, если вам
необходимо присвоить одинаковый вес каждому классу, рекомендуется
использовать макро-усреднение f1-меры:


В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?

CatBoost обладает гибкостью, позволяя задавать индексы категориальных столбцов, чтобы его можно было кодировать как кодирование в одно касание с использованием one_hot_max_size (используйте кодирование в одно касание для всех функций с числом различных значений, меньшим или равным данному значению параметра).

LightGBM также может обрабатывать категориальные функции, вводя имена функций. Он не конвертируется в одноразовое кодирование и намного быстрее, чем одноразовое кодирование. 

В отличие от CatBoost или LGBM, XGBoost не может обрабатывать категориальные функции сам по себе, он принимает только числовые значения, подобные случайному лесу. Поэтому перед подачей категориальных данных в XGBoost необходимо выполнить различные кодировки, такие как кодирование меток, среднее кодирование или однократное кодирование.